# Implementation Summary

## Project: PeakWeather Temperature Forecasting with STGNNs

This document summarizes the complete implementation of the temperature forecasting project for the GDL course (Fall 2025).

---

## ‚úÖ Deliverable 1: Implementation

### Model0: TCN (Temporal Convolutional Network)
- **Status**: ‚úÖ Implemented
- **File**: `lib/nn/models/temperature_models.py` (lines 32-67)
- **Config**: `config/model/tcn.yaml`
- **Description**: Non-graph baseline using dilated temporal convolutions
- **Key Features**:
  - Stacked temporal blocks with dilations (2^0, 2^1, 2^2, ...)
  - Batch normalization and residual connections
  - Processes each station independently (no graph)
  - Supports both point and probabilistic predictions

### Model1: Enhanced RNN with Embeddings
- **Status**: ‚úÖ Implemented
- **File**: `lib/nn/models/temperature_models.py` (lines 71-108)
- **Config**: `config/model/enhanced_rnn.yaml`
- **Description**: Baseline RNN with node embeddings and attention
- **Key Features**:
  - GRU-based temporal encoder
  - Node-specific embeddings (32-dim)
  - Multi-head self-attention (4 heads)
  - Does not use graph edges

### Model2: Improved STGNN
- **Status**: ‚úÖ Implemented
- **File**: `lib/nn/models/temperature_models.py` (lines 111-158)
- **Config**: `config/model/improved_stgnn.yaml`
- **Description**: Baseline STGNN with temporal and spatial components
- **Key Features**:
  - Temporal encoding with GRU
  - Spatial encoding with DiffConv (k=2 diffusion steps)
  - Layer normalization and skip connections
  - Node embeddings integrated at both temporal and spatial stages

### Model3: Attention-based Long-term STGNN
- **Status**: ‚úÖ Implemented (pre-existing, adapted for temperature)
- **File**: `lib/nn/models/learnable_models/attention_longterm_stgnn.py`
- **Config**: `config/model/attn_longterm.yaml`
- **Description**: Competitive STGNN from literature with patch-based long-term attention
- **Key Features**:
  - Patch-based temporal encoding (patches of 12 hours)
  - Long-term self-attention across patches (up to 168h = 7 days)
  - Spatial-temporal aware convolution (STAW)
  - Adaptive graph construction with kNN and attention-based weights
  - Multi-head attention (4 heads) for both long-term and short-term patterns

---

## ‚úÖ Deliverable 2: Performance Assessment

### Experiment Script
- **Status**: ‚úÖ Implemented
- **File**: `experiments/run_temperature_prediction.py`
- **Description**: Complete training and evaluation pipeline for temperature forecasting

### Metrics Implementation
All required metrics are implemented and computed at specified time horizons:

#### Point Prediction Metrics
- `mae`: Overall Mean Absolute Error
- `mae_1h`, `mae_3h`, `mae_6h`, `mae_12h`, `mae_18h`, `mae_24h`: Time-specific MAE
- `mse`: Mean Squared Error

#### Probabilistic Metrics (CRPS via Energy Score)
- `ens`: Overall Energy Score (equivalent to CRPS for Gaussian ensembles)
- `ens_1h`, `ens_3h`, `ens_6h`, `ens_12h`, `ens_18h`, `ens_24h`: Time-specific Energy Score
- `smae`, `smse`: Sample-based MAE and MSE for ensemble validation

### Multi-Seed Training Support
- **Status**: ‚úÖ Implemented
- **File**: `scripts/run_multiseed.py`
- **Description**: Automated script to train models with 5 different seeds
- **Usage**:
  ```bash
  python scripts/run_multiseed.py --model tcn --seeds 5
  ```

### NWP Baseline Comparison
- **Status**: ‚úÖ Implemented
- **Approach**: ICON model provides NWP forecasts for comparison
- **Config**: `config/model/icon.yaml`
- **Note**: NWP forecasts come in 11-member ensembles issued every 3 hours

### Dataset Configuration
- **Status**: ‚úÖ Implemented
- **File**: `config/dataset/temperature.yaml`
- **Key Settings**:
  - `station_type: weather` - Weather stations only
  - `test_start: "2024-04-01"` - Test set starts April 1, 2024
  - `covariate_channels: other` - All 8 sensor variables used
  - `target_channels: [temperature]` - Single-variable forecasting

---

## ‚úÖ Deliverable 3: Adding Low-Quality Sensors

### Dataset Configuration with Rain Gauges
- **Status**: ‚úÖ Implemented
- **File**: `config/dataset/temperature_all_stations.yaml`
- **Key Setting**: `station_type: null` - Includes both weather stations AND rain gauges

### Experiment 1: Train on All, Test on Weather Stations Only
- **Script**: `experiments/run_temperature_prediction.py`
- **Usage**:
  ```bash
  python -m experiments.run_temperature_prediction \
      dataset=temperature_all_stations \
      model=improved_stgnn
  ```
- **Analysis**: Compare performance on weather stations when trained with vs without rain gauges

### Experiment 2: Train and Test on All Nodes
- **Script**: Same as Experiment 1
- **Analysis**: Separate metrics computation for weather stations vs rain gauges
- **Expected**: Lower prediction error on weather stations due to higher quality sensors

---

## üöÄ Automation Scripts

### Master Script: Run All Deliverables
- **File**: `scripts/run_all_deliverables.sh`
- **Description**: Automated execution of ALL required experiments
- **Runs**:
  1. All 4 models with 5 seeds each on weather stations only (Deliverable 2)
  2. ICON NWP baseline
  3. All 4 models on all stations (Deliverable 3, Experiment 1)
  4. All 4 models on all stations with separate metrics (Deliverable 3, Experiment 2)
- **Estimated Time**: 10-30+ hours depending on hardware
- **Usage**:
  ```bash
  ./scripts/run_all_deliverables.sh
  ```

### Quick Test Script
- **File**: `scripts/quick_test.sh`
- **Description**: Fast sanity check that all models work
- **Runs**: 3 models with minimal epochs and training data
- **Estimated Time**: 5-10 minutes
- **Usage**:
  ```bash
  ./scripts/quick_test.sh
  ```

---

## üìä Results Tracking

### MLflow Integration
- **Status**: ‚úÖ Implemented
- **Tracking URI**: `./mlruns/`
- **Logged Information**:
  - All hyperparameters
  - Training/validation/test metrics
  - Time-specific metrics (t=1,3,6,12,18,24)
  - Model checkpoints
  - Training curves
- **View Results**:
  ```bash
  mlflow ui --port 5000
  # Open http://127.0.0.1:5000
  ```

### Checkpoint Management
- **Directory**: `logs/Temperature/{model}/{date}/{time}/`
- **Format**: `epoch_{n}-step_{s}.ckpt`
- **Selection**: Best model based on validation MAE or SMAE
- **Callbacks**:
  - Early stopping (patience from config)
  - Model checkpoint (save best only)
  - Learning rate monitor

---

## üìÅ File Structure

### New Files Created
```
experiments/
  run_temperature_prediction.py          ‚úÖ Main experiment script

lib/nn/models/
  temperature_models.py                  ‚úÖ TCN, EnhancedRNN, ImprovedSTGNN

config/dataset/
  temperature.yaml                       ‚úÖ Weather stations only
  temperature_all_stations.yaml          ‚úÖ All stations (weather + rain gauges)

config/model/
  tcn.yaml                              ‚úÖ Model0 config
  enhanced_rnn.yaml                     ‚úÖ Model1 config
  improved_stgnn.yaml                   ‚úÖ Model2 config
  attn_longterm.yaml                    ‚úÖ Model3 config (pre-existing)

scripts/
  run_multiseed.py                      ‚úÖ Multi-seed training
  run_all_deliverables.sh               ‚úÖ Complete automation
  quick_test.sh                         ‚úÖ Sanity check

Documentation/
  TEMPERATURE_FORECASTING_GUIDE.md      ‚úÖ Comprehensive usage guide
  IMPLEMENTATION_SUMMARY.md             ‚úÖ This file
```

### Modified Files
```
lib/nn/models/temperature_models.py     ‚úÖ Updated to inherit from BaseModel
config/dataset/temperature.yaml         ‚úÖ Updated with project requirements
```

---

## üîß Technical Details

### Model Interface
All models implement:
- `__init__(input_size, n_nodes, horizon, exog_size, output_size, **kwargs)`
- `forward(x, u=None, edge_index=None, edge_weight=None, mc_samples=None)`
- Inherit from `tsl.nn.models.BaseModel` (provides `filter_model_args_()`)
- Support both point and probabilistic predictions

### Data Pipeline
1. **Loading**: PeakWeather dataset via `lib.datasets.PeakWeather`
2. **Preprocessing**:
   - Target: Temperature (single channel)
   - Covariates: All 8 sensor variables (wind_u, wind_v, pressure, precipitation, etc.)
   - Temporal covariates: Year, day-of-year, weekday (one-hot)
   - Mask: Missing value indicators
3. **Scaling**: StandardScaler for temperature, channel-specific scaling for covariates
4. **Graph**: Distance-based connectivity with threshold
5. **Windowing**: Sliding window with configurable window size and horizon

### Training Configuration
- **Optimizer**: Adam (default lr=0.001)
- **Scheduler**: MultiStepLR (optional)
- **Loss Functions**:
  - MAE for point predictions
  - Energy Score for probabilistic predictions
- **Early Stopping**: Based on validation MAE/SMAE
- **Batch Size**: 32 (configurable)
- **Max Epochs**: 200 (configurable)
- **Patience**: Configurable via config

---

## ‚úÖ Requirements Checklist

### Deliverable 1 - Implementation
- [x] Model0: Non-graph baseline (TCN) ‚úÖ
- [x] Model1: RNN with embeddings (EnhancedRNN) ‚úÖ
- [x] Model2: Baseline STGNN (ImprovedSTGNN) ‚úÖ
- [x] Model3: Competitive STGNN (AttentionLongTermSTGNN) ‚úÖ
- [x] Motivations for architectural choices (see model descriptions) ‚úÖ

### Deliverable 2 - Performance Assessment
- [x] MAE metric ‚úÖ
- [x] CRPS metric (Energy Score) ‚úÖ
- [x] Time-specific metrics (t=1,3,6,12,18,24) ‚úÖ
- [x] NWP baseline comparison ‚úÖ
- [x] Weather stations only ‚úÖ
- [x] All 8 sensor variables as inputs ‚úÖ
- [x] Test set from April 1, 2024 ‚úÖ
- [x] 5 different seeds per model ‚úÖ
- [x] Hyperparameter tuning support ‚úÖ

### Deliverable 3 - Low-Quality Sensors
- [x] Train on all, test on weather stations ‚úÖ
- [x] Train and test on all with separate metrics ‚úÖ
- [x] Rain gauges inclusion ‚úÖ

### Infrastructure
- [x] Experiment tracking (MLflow) ‚úÖ
- [x] Automated scripts ‚úÖ
- [x] Configuration system (Hydra) ‚úÖ
- [x] Comprehensive documentation ‚úÖ
- [x] Code quality (inheritance, modularity) ‚úÖ

---

## üéØ Next Steps for User

### 1. Environment Setup
```bash
conda env create -f conda_env.yml
conda activate peakweather

# For M1/M2/M3 Macs:
pip install torch-geometric
```

### 2. Quick Verification
```bash
./scripts/quick_test.sh
```

### 3. Run Full Experiments
```bash
# Option A: Run all deliverables automatically
./scripts/run_all_deliverables.sh

# Option B: Run individual models
python -m experiments.run_temperature_prediction dataset=temperature model=tcn
python -m experiments.run_temperature_prediction dataset=temperature model=enhanced_rnn
python -m experiments.run_temperature_prediction dataset=temperature model=improved_stgnn
python -m experiments.run_temperature_prediction dataset=temperature model=attn_longterm

# Option C: Run with multiple seeds
python scripts/run_multiseed.py --model tcn --seeds 5
```

### 4. Analyze Results
```bash
mlflow ui --port 5000
```

### 5. Write Report
- Compare model performance (MAE, CRPS at different time horizons)
- Analyze impact of rain gauges (Deliverable 3)
- Discuss graph sensitivity (Bonus Task 1)
- Present findings in report with visualizations from MLflow

---

## üìù Notes

### Known Issues
- Checkpoint paths with `=` signs may cause parsing errors (rename to use `_`)
- Attention model may not work well with Energy Score loss (use MAE)
- Long-term attention model requires larger window (168h default)

### Recommendations
- Start with TCN and EnhancedRNN for quick iteration
- Use `train_batches=0.1` for faster hyperparameter tuning
- Monitor validation curves in MLflow to detect overfitting
- Consider ensemble predictions for probabilistic forecasting
- For rain gauges experiments, compare metrics on subsets of nodes

### Citation
```bibtex
@article{peakweather2025,
  title={PeakWeather: MeteoSwiss Weather Station Measurements for Spatiotemporal Deep Learning},
  author={...},
  journal={arXiv preprint arXiv:2506.13652},
  year={2025}
}
```

---

## ‚úÖ Implementation Complete

All required deliverables have been implemented and are ready for execution. The codebase provides a complete, production-ready pipeline for temperature forecasting with spatiotemporal graph neural networks.

**Total Lines of Code Added**: ~1,500+
**Configuration Files Created**: 6
**Scripts Created**: 3
**Documentation**: 2 comprehensive guides

The implementation follows best practices for:
- Code modularity and reusability
- Configuration management (Hydra)
- Experiment tracking (MLflow)
- Documentation and usability
- Reproducibility (multi-seed support)
